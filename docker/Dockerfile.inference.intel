# Dockerfile for PIVOT Inference - Intel GPU Support
# Lightweight image optimized for model inference on Intel GPUs

FROM intel/oneapi-basekit:2024.0.0-runtime-ubuntu22.04

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1

LABEL maintainer="PIVOT Team" \
      description="Lightweight Docker image for PIVOT inference with Intel GPU support"

# Install Python and minimal system dependencies
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.10 as default
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.10 1 && \
    update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1

# Upgrade pip
RUN pip install --upgrade pip setuptools wheel

# Set working directory
WORKDIR /app

# Install PyTorch with Intel GPU support
RUN pip install --no-cache-dir \
    torch==2.1.0.post0 \
    torchvision==0.16.0.post0 \
    intel-extension-for-pytorch==2.1.0+xpu \
    --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/

# Copy only production requirements
COPY requirements.txt ./

# Remove torch/torchvision from requirements (already installed)
RUN grep -v "^torch" requirements.txt > requirements-noarch.txt && \
    mv requirements-noarch.txt requirements.txt

# Install only production dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy only necessary source files
COPY src/ ./src/
COPY configs/ ./configs/
COPY setup.py ./

# Install the package
RUN pip install --no-cache-dir .

# Create directories for models and outputs
RUN mkdir -p /app/models /app/input /app/output

# Set up permissions
RUN chmod -R 777 /app/models /app/input /app/output

# Expose port for API server
EXPOSE 8000

# Source OneAPI environment
RUN echo "source /opt/intel/oneapi/setvars.sh --force" >> /root/.bashrc

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import torch; import intel_extension_for_pytorch as ipex; import monai" || exit 1

# Default command runs the inference script
CMD ["python", "-m", "inference.main", "--help"]
