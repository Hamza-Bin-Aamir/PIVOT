# Training Configuration
train:
  # Data settings
  data_dir: "data/processed"
  batch_size: 2
  num_workers: 4
  pin_memory: true  # Pin memory for faster GPU transfer
  patch_size: [96, 96, 96]  # Patch size for training (D, H, W)
  patches_per_volume: 16  # Number of patches to sample per volume per epoch
  positive_fraction: 0.5  # Fraction of patches centered on nodules
  cache_size: 4  # Number of volumes to keep in memory cache

  # Model settings
  model:
    type: "unet3d"
    in_channels: 1
    out_channels: 1
    init_features: 32
    depth: 4

  # Training hyperparameters
  epochs: 100
  learning_rate: 0.0001
  weight_decay: 0.00001
  precision: "32"  # Options: "32" (FP32), "16-mixed" (FP16), "bf16-mixed" (BF16)

  # Hard negative mining (for center detection)
  use_hard_negative_mining: false  # Enable Online Hard Example Mining (OHEM)
  hard_negative_ratio: 3.0  # Ratio of hard negatives to positives
  min_negative_samples: 100  # Minimum hard negatives to mine

  # Optimizer settings
  optimizer:
    type: "adam"
    betas: [0.9, 0.999]

  # Scheduler settings
  scheduler:
    type: "cosine"
    min_lr: 0.000001

  # Loss function
  loss:
    type: "dice"

  # Checkpointing
  checkpoint_dir: "checkpoints"
  save_every: 10

  # Logging
  log_dir: "logs"
  log_every: 10

  # Experiment tracking
  wandb:
    enabled: false
    project: "pivot"
    entity: ""

# Data preprocessing
preprocessing:
  target_spacing: [1.0, 1.0, 1.0]
  window_center: -600
  window_width: 1500
  patch_size: [96, 96, 96]

# Inference settings
inference:
  batch_size: 1
  overlap: 0.5
  threshold: 0.5
